[ General ]

  Frequency = 3000
;      Frequency in MHz for the x86 Cpu. Value between 1 and 10K.
  Cores = 1
  Threads = 1
;      Number of hardware threads per core. The total number of computing nodes
;      in the Cpu model is equals to Cores * Threads.
;  FastForward = 50000000
;      Number of x86 instructions to run with a fast functional simulation before
;      the architectural simulation starts.
;  ContextQuantum = <cycles> (Default = 100k)
;      If ContextSwitch is true, maximum number of cycles that a context can occupy
;      a Cpu hardware thread before it is replaced by other pending context.
;  RecoverKind = {Writeback|Commit} (Default = Writeback)
;      On branch misprediction, stage in the execution of the mispredicted branch
;      when processor recovery is triggered.
;  RecoverPenalty = <cycles> (Default = 0)
;      Number of cycles that the fetch stage gets stalled after a branch
;      misprediction.
;  PageSize = <size> (Default = 4kB)
;      Memory page size in bytes.
;  DataCachePerfect = {t|f} (Default = False)
;  ProcessPrefetchHints = {t|f} (Default = True)
;      If specified as false, the cpu will ignore any prefetch hints/instructions.
;  PrefetchHistorySize = <size> (Default = 10)
;      Number of past prefetches to keep track of, so as to avoid redundant prefetches
;      from being issued from the cpu to the cache module.
;  InstructionCachePerfect = {t|f} (Default = False)
;      Set these options to true to simulate a perfect data/instruction caches,
;      respectively, where every access results in a hit. If set to false, the
;      parameters of the caches are given in the memory configuration file
;  UseNCStore = {t|f} (Default = False)
;      Normally the Cpu uses cohnerency-enabled Store commands.  Setting this to True
;      causes the Cpu to issue NCStore commands to reduce protocol overhead.
;      When True, Cores and Threads must be set to 1.

[ Pipeline ]

;  FetchKind = {Shared|TimeSlice} (Default = TimeSlice)
;      Policy for fetching instruction from different threads. A shared fetch stage
;      fetches instructions from different threads in the same cycle; a time-slice
;      fetch switches between threads in a round-robin fashion.
  DecodeWidth = 4
;      Number of x86 instructions decoded per cycle.
;  DispatchKind = {Shared|TimeSlice} (Default = TimeSlice)
;      Policy for dispatching instructions from different threads. If shared,
;      instructions from different threads are dispatched in the same cycle. Otherwise,
;      instruction dispatching is done in a round-robin fashion at a cycle granularity.
  DispatchWidth = 4
;      Number of microinstructions dispatched per cycle.
;  IssueKind = {Shared|TimeSlice} (Default = TimeSlice)
;      Policy for issuing instructions from different threads. If shared, instructions
;      from different threads are issued in the same cycle; otherwise, instruction issue
;      is done round-robin at a cycle granularity.
  IssueWidth = 6
;      Number of microinstructions issued per cycle.
;  CommitKind = {Shared|TimeSlice} (Default = Shared)
;      Policy for committing instructions from different threads. If shared,
;      instructions from different threads are committed in the same cycle; otherwise,
;      they commit in a round-robin fashion.
  CommitWidth = 4
;      Number of microinstructions committed per cycle.
;  OccupancyStats = {t|f} (Default = False)
;      Calculate structures occupancy statistics. Since this computation requires
;      additional overhead, the option needs to be enabled explicitly. These statistics
;      will be attached to the Cpu report.

[ Queues ]

  FetchQueueSize = 128
;      Size of the fetch queue given in bytes.
  UopQueueSize = 64
;      Size of the uop queue size, given in number of uops.
;  RobKind = {Private|Shared} (Default = Private)
;      Reorder buffer sharing among hardware threads.
  RobSize = 160
; 64
;      Reorder buffer size in number of microinstructions (if private, per-thread size).
;  IqKind = {Private|Shared} (Default = Private)
;      Instruction queue sharing among threads.
  IqSize = 64 
; 40
;      Instruction queue size in number of uops (if private, per-thread IQ size).
;  LsqKind = {Private|Shared} (Default = 20)
;      Load-store queue sharing among threads.
  LsqSize = 48
; 20
;      Load-store queue size in number of uops (if private, per-thread LSQ size).
;  RfKind = {Private|Shared} (Default = Private)
;      Register file sharing among threads.
  RfIntSize = 128
; 80
;      Number of integer physical register (if private, per-thread).
  RfFpSize = 80
; 40
;      Number of floating-point physical registers (if private, per-thread).
  RfXmmSize = 80
;40
;      Number of XMM physical registers (if private, per-thread).

;[ TraceCache ]

;  Present = {t|f} (Default = False)
;      If true, a trace cache is included in the model. If false, the rest of the
;      options in this section are ignored.
;  Sets = <num_sets> (Default = 64)
;      Number of sets in the trace cache.
;  Assoc = <num_ways> (Default = 4)
;      Associativity of the trace cache. The product Sets * Assoc is the total
;      number of traces that can be stored in the trace cache.
;  TraceSize = <num_uops> (Default = 16)
;      Maximum size of a trace of uops.
;  BranchMax = <num_branches> (Default = 3)
;      Maximum number of branches contained in a trace.
;  QueueSize = <num_uops> (Default = 32)
;      Size of the trace queue size in uops.

[ FunctionalUnits ]

;  The possible variables in this section follow the format
;      <func_unit>.<field> = <value>
;  where <func_unit> refers to a functional unit type, and <field> refers to a
;  property of it. Possible values for <func_unit> are:

;      IntAdd      Integer adder
;      IntMult     Integer multiplier
;      IntDiv      Integer divider

;      EffAddr     Operator for effective address computations
;      Logic       Operator for logic operations

;      FloatSimple    Simple floating-point operations
;      FloatAdd       Floating-point adder
;      FloatComp      Floating-point comparator
;      FloatMult      Floating-point multiplier
;      FloatDiv       Floating-point divider
;      FloatComplex   Operator for complex floating-point computations

;      XMMIntAdd      XMM integer adder
;      XMMIntMult     XMM integer multiplier
;      XMMIntDiv      XMM integer Divider

;      XMMLogic       XMM logic operations

;      XMMFloatAdd       XMM floating-point adder
;      XMMFloatComp      XMM floating-point comparator
;      XMMFloatMult      XMM floating-point multiplier
;      XMMFloatDiv       XMM floating-point divider
;      XMMFloatConv      XMM floating-point converter
;      XMMFloatComplex   Complex XMM floating-point operations

;  Possible values for <field> are:
;      Count       Number of functional units of a given kind.
;      OpLat       Latency of the operator.
;      IssueLat    Latency since an instruction was issued until the functional
;                  unit is available for the next use. For pipelined operators,
;                  IssueLat is smaller than OpLat.
;

  IntAdd.Count = 4
  IntAdd.OpLat = 1
  IntAdd.IssueLat = 1

  IntMult.Count = 2
  IntMult.OpLat = 1
  IntMult.IssueLat = 1

  IntDiv.Count = 2
  IntDiv.OpLat = 4
  IntDiv.IssueLat = 1

  EffAddr.Count = 4
  EffAddr.OpLat = 1
  EffAddr.IssueLat = 1 

  Logic.Count = 4
  Logic.OpLat = 1
  Logic.IssueLat = 1

  FloatSimple.OpLat = 2
  FloatSimple.IssueLat = 1
  
  FloatAdd.OpLat = 2
  FloatAdd.IssueLat = 1
  
  FloatCompare.OpLat = 2
  FloatCompare.IssueLat = 1

  FloatMult.OpLat = 4
  FloatMult.IssueLat = 1

  FloatDiv.OpLat = 8
  FloatDiv.IssueLat = 4

  FloatComplex.OpLat = 8
  FloatComplex.IssueLat = 8


[ BranchPredictor ]

  Kind = TwoLevel
;  Kind = {Perfect|Taken|NotTaken|Bimodal|TwoLevel|Combined} (Default = TwoLevel)
;      Branch predictor type.
  BTB.Sets = 256
;      Number of sets in the BTB.
  BTB.Assoc = 4
;      BTB associativity.
  Bimod.Size = 1024
;      Number of entries of the bimodal branch predictor.
;  Choice.Size = 1024
;      Number of entries for the choice predictor.
  RAS.Size = 32
;      Number of entries of the return address stack (RAS).
  TwoLevel.L1Size = 1
;      For the two-level adaptive predictor, level 1 size.
  TwoLevel.L2Size = 1024
;      For the two-level adaptive predictor, level 2 size.
  TwoLevel.HistorySize = 8
;      For the two-level adaptive predictor, level 2 history size.

